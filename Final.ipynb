{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv #Import csv\n",
    "from datetime import datetime\n",
    "import jsonpickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Google Trend API Wrapper\n",
    "from pytrends.request import TrendReq\n",
    "pytrends = TrendReq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogleTrendsNSDxMT(kw_list):\n",
    "    \"\"\" Args:\n",
    "        kw_list ([str]): keywords used in Google Trends, 'National Sandwich Day, Me Too'   \n",
    "        \n",
    "    Returns:\n",
    "        GoogleTrendsNSDxMT_chart: line graph depicting search of keywords over time\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: Opps, something went wrong. Please check your syntax and try again. \"\"\"\n",
    "    if KeywordError:\n",
    "        raise ValueError('Opps, something went wrong. Please check your syntax and try again')\n",
    "    if IndexError:\n",
    "        raise ValueError('Opps, something went wrong. Please check your syntax and try again')\n",
    "        \n",
    "        \n",
    "        \n",
    "    #search items\n",
    "    kw_list = [\"National Sandwich Day\", \"Me too\"] \n",
    "    \n",
    "    #load paramaters for data, not necessary for all GoogleTrends API uses\n",
    "    pytrends.build_payload(kw_list, timeframe='now 7-d', geo='US') \n",
    "    \n",
    "    #actual pulling of data \n",
    "    GoogleTrendsNSDxMT_df=pytrends.interest_over_time()\n",
    "    \n",
    "    #parsing dataframe to the relevant columns\n",
    "    GoogleTrendsNSDxMT_df=GoogleTrendsNSDxMT_df[['National Sandwich Day', 'Me too']]\n",
    "    \n",
    "    #plot chart\n",
    "    GoogleTrendsNSDxMT_chart= GoogleTrendsNSDxMT_df.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GoogleTrendsiPXxWSG7(kw_list):\n",
    "    \"\"\" Args:\n",
    "        kw_list ([str]): keywords used in Google Trends, 'IPhone X, World Series Game 7'   \n",
    "        \n",
    "    Returns:\n",
    "        GoogleTrendsiPXxWSG7_chart: line graph depicting search of keywords over time\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: Opps, something went wrong. Please check your syntax and try again. \"\"\"\n",
    "    if KeywordError:\n",
    "        raise ValueError('Opps, something went wrong. Please check your syntax and try again')\n",
    "    if IndexError:\n",
    "        raise ValueError('Opps, something went wrong. Please check your syntax and try again')\n",
    "        \n",
    "    \n",
    "    #search items\n",
    "    kw_list= [ \"iPhone X\",\"World Series Game 7\"]\n",
    "    \n",
    "    #load parameters for data pull, not necessary for all Google Trends API uses\n",
    "    pytrends.build_payload(kw_list, timeframe='now 7-d', geo='US')\n",
    "    \n",
    "    #actual pulling of data\n",
    "    GoogleTrendsiPXxWSG7_df=pytrends.interest_over_time()\n",
    "    \n",
    "    #parsing dataframe down to relevant columns\n",
    "    GoogleTrendsiPXxWSG7_df=GoogleTrendsiPXxWSG7_df[['iPhone X', 'World Series Game 7']]\n",
    "    \n",
    "    #plot chart\n",
    "    GoogleTrendsiPXxWSG7_chart= GoogleTrendsiPXxWSG7_df.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleTrendsNSDxMT(['National Sandwich Day','Me too'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleTrendsiPXxWSG7(['iPhone X','World Series Game 7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Consumer Key \n",
    "API_KEY= 'QjyJ4Aa8xTm6Yyok0xHYC7q1b'\n",
    "#Consumer Secret (Hey Don't Look!)\n",
    "API_SECRET= 'QAKECWDILlUVQmwxmgzEfb50ajUdXuFhmkIbHbfhN6eXH9b9y2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Access Twitter, using AppAuth instead of OAuth to increase speed\n",
    "auth = tweepy.AppAuthHandler(API_KEY, API_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,\n",
    "                   wait_on_rate_limit_notify=True)\n",
    "\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hashtag_tweets(hashtag):\n",
    "     \"\"\" Args:\n",
    "        hashtag (str): hashtag whose tweets you want to grab   \n",
    "        \n",
    "    Returns:\n",
    "        hashtag_tweets_chart: line graph depicting use of hashtag on a per hour basis over the course of a week\n",
    "        hashtag_tweets.csv: csv file containing the timestamp of every tweet using the hashtag over 7 days and a count of total tweets for the hashtag\n",
    "        \n",
    "    Raises:\n",
    "        TweepError: \"some error : \" + str(TweepError) \"\"\"\n",
    "    \n",
    "    searchQuery = hashtag  # this is what we're searching for\n",
    "    maxTweets = 10000000 # Some arbitrary large number\n",
    "    tweetsPerQry = 100  # this is the max the API permits\n",
    "    fname = 'hashtag_tweets.csv' #file to save tweet info\n",
    "    \n",
    "    csvFile = open('hashtag_tweets.csv', 'a') #open file where tweet info will be stored \n",
    "    csvwriter= csv.writer(csvFile, delimiter=' ') #automatically reads tweet data and parses\n",
    "    csvwriter.writerow(['DateTime']) #only show the Timestamp for the tweets\n",
    "\n",
    "    # If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "    # else default to no lower limit, go as far back as API allows\n",
    "    sinceId = None\n",
    "\n",
    "    # If results only below a specific ID are, set max_id to that ID.\n",
    "    # else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "    max_id = (-1)\n",
    "\n",
    "    tweetCount = 0\n",
    "    print(\"Downloading max {0} tweets\".format(maxTweets)) #Graphical help to show progress\n",
    "    with open(fname, 'w') as f:\n",
    "        while tweetCount < maxTweets:\n",
    "            try:\n",
    "                if (max_id <= 0):\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry)\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                since_id=sinceId)\n",
    "                else:\n",
    "                    if (not sinceId):\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1))\n",
    "                    else:\n",
    "                        new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                                max_id=str(max_id - 1),\n",
    "                                                since_id=sinceId)\n",
    "                if not new_tweets:\n",
    "                    print(\"No more tweets found\")\n",
    "                    break\n",
    "                for tweet in new_tweets:\n",
    "                     csvwriter.writerow([tweet.created_at]) #recording the tweet info\n",
    "                tweetCount += len(new_tweets)\n",
    "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                max_id = new_tweets[-1].id\n",
    "            except tweepy.TweepError as e:\n",
    "                # Just exit if any error\n",
    "                print(\"some error : \" + str(e))\n",
    "                break\n",
    "\n",
    "    print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fname))\n",
    "    \n",
    "    csvFile.close()\n",
    "    \n",
    "    hashtag_tweets_df= pd.read_csv('../FinalProject/hashtag_tweets.csv') #read tweet info\n",
    "    hashtag_tweets_df.insert(1, 'Tweet Count', range(len(hashtag_tweets_df))) #insert column to count tweets\n",
    "    hashtag_tweets_df['DateTime'] = pd.to_datetime(hashtag_tweets_df['DateTime']) #making sure it recognizes the entries as timestamps\n",
    "   \n",
    "    ts = hashtag_tweets_df.set_index('DateTime')\n",
    "    hashtag_tweets_df= ts.resample('H').count() #shows the count of number of entries per hour, will help with graphical processing\n",
    "    \n",
    "    hashtag_tweets_chart=hashtag_tweets_df.plot.line(legend=False) #plot the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag_tweets('#GoGreater') #small test hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag_tweets('#iPhone5s') #larger test hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_tweets('#nationalsandwichday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_tweets('#metoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag_tweets('#iphoneX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag_tweets('#worldseriesgame7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
